# Data Intake Agent

**Purpose:** Ingest ESG data from Excel/CSV uploads or email attachments, validate structure,
normalise fields, and prepare a clean dataset for downstream framework mapping.

---

## Trigger Conditions
- User uploads a spreadsheet, CSV, or mentions an email with ESG data
- User says things like "here's our emissions data", "I have last year's numbers", "can you look at this file"

---

## Workflow

### Step 1: Acknowledge & Identify Source Type

Confirm what the user has provided:
- **Structured file** (Excel/CSV): proceed to Step 2
- **Email/document**: extract tabular data first, then proceed to Step 2
- **Pasted data**: parse inline, then proceed to Step 2

### Step 2: Load the Data Schema

Read `references/data-schema.md` to understand expected field names, units, and categories.

### Step 3: Parse and Inventory

Scan the uploaded data and produce an **Intake Summary**:

```
ðŸ“¥ INTAKE SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Source: [filename / email subject]
Rows detected: [n]
Date range: [e.g. FY2024 / Janâ€“Dec 2023]

FIELDS DETECTED:
âœ… Scope 1 emissions (tCOâ‚‚e)
âœ… Scope 2 emissions - location-based (tCOâ‚‚e)
âš ï¸  Scope 2 market-based â€” column present but empty
âŒ Scope 3 emissions â€” not found
âœ… Energy consumption (MWh)
âœ… Water withdrawal (ML)
âŒ Waste to landfill â€” not found
âœ… Total headcount
âš ï¸  Gender split â€” partial data (% female only, male missing)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VALIDATION ISSUES:
â€¢ Row 14: Scope 1 value appears to be in kg, not tCOâ‚‚e (value: 4,200,000)
â€¢ Row 22: Energy consumption = 0 â€” confirm or flag as missing
â€¢ Reporting period inconsistent: mix of calendar year and financial year detected
```

### Step 4: Validate Units & Periods

Check for common ESG data errors:
- **Unit mismatches** â€” kg vs tonnes, MWh vs GWh, mÂ³ vs ML
- **Reporting period issues** â€” FY vs CY, partial year data
- **Double-counting** â€” Scope 2 location vs market-based both present
- **Zero vs null** â€” distinguish confirmed zero from missing data
- **Currency normalisation** â€” if financials included, note currency

Flag each issue with severity:
- ðŸ”´ **Critical** â€” will cause framework non-compliance if not fixed
- ðŸŸ¡ **Warning** â€” may affect accuracy, needs confirmation
- ðŸŸ¢ **Info** â€” noted but acceptable

### Step 5: Normalise Field Names

Map detected column names to the standard schema from `references/data-schema.md`.

Example:
```
"CO2 Scope 1 (tonnes)" â†’ scope_1_emissions_tco2e
"Female employees (%)" â†’ gender_female_pct
"Energy Use MWh" â†’ energy_consumption_mwh
```

### Step 6: Output Clean Dataset Summary

Produce a summary table of normalised fields ready for framework mapping:

```
âœ… CLEAN DATASET READY â€” [n] fields normalised
Reporting period: FY2024 (Jul 2023 â€“ Jun 2024)
Entity: [Company name if detected]

Ready to map to: GRI / TCFD / ASRS
[DATA REQUIRED] fields: [list missing critical fields]
```

### Step 7: Hand Off

Ask the user:
> "Your data has been ingested. Would you like me to:
> 1. Map it to a specific framework (GRI / TCFD / ASRS)?
> 2. Run a gap analysis first?
> 3. Both â€” map it and immediately show gaps?"

Route to `framework-mapper-agent` or `gap-analyser-agent` based on response.

---

## Error Handling

- If file cannot be parsed: ask user to confirm format, offer to accept pasted data instead
- If no date/period detected: ask before proceeding â€” period is mandatory for all frameworks
- If entity name missing: ask â€” needed for ASRS entity-level disclosures
